// stdlib/ai/train.berk
// Training Utilities & Loops
// PyTorch training loop helpers
//
// Performance: GPU acceleration, mixed precision, gradient accumulation

import "ai/tensor" as tensor
import "ai/nn" as nn
import "ai/optim" as optim
import "ai/data" as data
import "time" as time
import "collections" as collections

// ============================================================================
// TRAINER
// ============================================================================

/// Training configuration
pub struct TrainConfig {
    pub epochs: u64,
    pub learning_rate: f32,
    pub batch_size: u64,
    pub device: tensor.Device,
    pub mixed_precision: bool,
    pub gradient_accumulation_steps: u64,
    pub max_grad_norm: f32,
    pub early_stopping_patience: u64,
    pub checkpoint_dir: str,
    pub log_interval: u64,
}

impl TrainConfig {
    pub fn default() -> TrainConfig {
        TrainConfig {
            epochs: 10,
            learning_rate: 0.001,
            batch_size: 32,
            device: tensor.Device.CPU,
            mixed_precision: false,
            gradient_accumulation_steps: 1,
            max_grad_norm: 1.0,
            early_stopping_patience: 5,
            checkpoint_dir: "checkpoints",
            log_interval: 10,
        }
    }
}

/// Trainer for supervised learning
pub struct Trainer {
    model: Box<dyn nn.Module>,
    optimizer: Box<dyn optim.Optimizer>,
    loss_fn: Box<dyn nn.Loss>,
    config: TrainConfig,
    history: TrainingHistory,
}

impl Trainer {
    pub fn new(
        model: Box<dyn nn.Module>,
        optimizer: Box<dyn optim.Optimizer>,
        loss_fn: Box<dyn nn.Loss>,
        config: TrainConfig
    ) -> Trainer {
        Trainer {
            model: model.to(config.device),
            optimizer: optimizer,
            loss_fn: loss_fn,
            config: config,
            history: TrainingHistory.new(),
        }
    }
    
    /// Train for one epoch
    pub fn train_epoch(
        self,
        train_loader: data.DataLoader,
        epoch: u64
    ) -> f32 {
        self.model.train()
        let mut total_loss = 0.0
        let mut num_batches = 0
        
        for (batch_idx, (inputs, targets)) in train_loader.iter().enumerate() {
            // Move to device
            let inputs = inputs.to(self.config.device)
            let targets = targets.to(self.config.device)
            
            // Forward pass
            let outputs = self.model.forward(inputs)
            let loss = self.loss_fn.forward(outputs, targets)
            
            // Backward pass
            loss.backward()
            
            // Gradient accumulation
            if (batch_idx + 1) % self.config.gradient_accumulation_steps == 0 {
                // Gradient clipping
                if self.config.max_grad_norm > 0.0 {
                    clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)
                }
                
                // Optimizer step
                self.optimizer.step()
                self.optimizer.zero_grad()
            }
            
            total_loss += loss.item()
            num_batches += 1
            
            // Logging
            if batch_idx % self.config.log_interval == 0 {
                yaz("Epoch {} [{}/{}] Loss: {:.4f}",
                    epoch, batch_idx, train_loader.len(), loss.item())
            }
        }
        
        total_loss / num_batches as f32
    }
    
    /// Validate
    pub fn validate(
        self,
        val_loader: data.DataLoader
    ) -> (f32, f32) {
        self.model.eval()
        let mut total_loss = 0.0
        let mut correct = 0u64
        let mut total = 0u64
        
        tensor.no_grad(|| {
            for (inputs, targets) in val_loader.iter() {
                let inputs = inputs.to(self.config.device)
                let targets = targets.to(self.config.device)
                
                let outputs = self.model.forward(inputs)
                let loss = self.loss_fn.forward(outputs, targets)
                
                total_loss += loss.item()
                
                // Calculate accuracy
                let predicted = outputs.argmax(dim: 1)
                correct += (predicted == targets).sum().item() as u64
                total += targets.numel()
            }
        })
        
        let avg_loss = total_loss / val_loader.len() as f32
        let accuracy = correct as f32 / total as f32
        
        (avg_loss, accuracy)
    }
    
    /// Full training loop
    pub fn fit(
        self,
        train_loader: data.DataLoader,
        val_loader: Option<data.DataLoader> = None
    ) {
        let mut best_val_loss = f32.INFINITY
        let mut patience_counter = 0u64
        
        for epoch in 0..self.config.epochs {
            let start_time = time.now()
            
            // Train
            let train_loss = self.train_epoch(train_loader, epoch)
            
            // Validate
            let (val_loss, val_acc) = if let Some(loader) = val_loader {
                let (loss, acc) = self.validate(loader)
                yaz("Epoch {} - Train Loss: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}",
                    epoch, train_loss, loss, acc)
                (loss, acc)
            } else {
                yaz("Epoch {} - Train Loss: {:.4f}", epoch, train_loss)
                (0.0, 0.0)
            }
            
            let epoch_time = time.now() - start_time
            yaz("Epoch time: {:.2f}s", epoch_time)
            
            // Save history
            self.history.train_losses.push(train_loss)
            if val_loader.is_some() {
                self.history.val_losses.push(val_loss)
                self.history.val_accuracies.push(val_acc)
            }
            
            // Early stopping
            if val_loader.is_some() {
                if val_loss < best_val_loss {
                    best_val_loss = val_loss
                    patience_counter = 0
                    self.save_checkpoint("best_model.berk")
                } else {
                    patience_counter += 1
                    if patience_counter >= self.config.early_stopping_patience {
                        yaz("Early stopping triggered at epoch {}", epoch)
                        break
                    }
                }
            }
            
            // Checkpoint
            if epoch % 10 == 0 {
                self.save_checkpoint("checkpoint_epoch_{}.berk".format(epoch))
            }
        }
    }
    
    /// Save model checkpoint
    pub fn save_checkpoint(self, filename: str) {
        let path = "{}/{}".format(self.config.checkpoint_dir, filename)
        let state_dict = self.model.state_dict()
        // TODO: Save state_dict to file
        yaz("Checkpoint saved: {}", path)
    }
    
    /// Load model checkpoint
    pub fn load_checkpoint(self, filename: str) {
        let path = "{}/{}".format(self.config.checkpoint_dir, filename)
        // TODO: Load state_dict from file
        yaz("Checkpoint loaded: {}", path)
    }
    
    /// Get training history
    pub fn history(self) -> TrainingHistory {
        self.history
    }
}

// ============================================================================
// TRAINING HISTORY
// ============================================================================

pub struct TrainingHistory {
    pub train_losses: [f32],
    pub val_losses: [f32],
    pub val_accuracies: [f32],
}

impl TrainingHistory {
    pub fn new() -> TrainingHistory {
        TrainingHistory {
            train_losses: [],
            val_losses: [],
            val_accuracies: [],
        }
    }
    
    /// Plot training curves (if plotting available)
    pub fn plot(self) {
        // TODO: Plot with graphics module
        yaz("Train losses: {:?}", self.train_losses)
        yaz("Val losses: {:?}", self.val_losses)
        yaz("Val accuracies: {:?}", self.val_accuracies)
    }
}

// ============================================================================
// GRADIENT UTILITIES
// ============================================================================

/// Clip gradient norm (prevent exploding gradients)
pub fn clip_grad_norm_(parameters: [tensor.Tensor], max_norm: f32) -> f32 {
    let mut total_norm = 0.0
    
    for param in parameters {
        if let Some(grad) = param.grad() {
            let param_norm = grad.norm().item()
            total_norm += param_norm * param_norm
        }
    }
    
    total_norm = total_norm.sqrt()
    let clip_coef = max_norm / (total_norm + 1e-6)
    
    if clip_coef < 1.0 {
        for param in parameters {
            if let Some(grad) = param.grad() {
                grad.mul_(clip_coef)
            }
        }
    }
    
    total_norm
}

/// Clip gradient value
pub fn clip_grad_value_(parameters: [tensor.Tensor], clip_value: f32) {
    for param in parameters {
        if let Some(grad) = param.grad() {
            grad.clamp_(-clip_value, clip_value)
        }
    }
}

// ============================================================================
// METRICS
// ============================================================================

pub mod metrics {
    /// Accuracy (classification)
    pub fn accuracy(predictions: tensor.Tensor, targets: tensor.Tensor) -> f32 {
        let correct = (predictions.argmax(dim: 1) == targets).sum()
        correct.item() as f32 / targets.numel() as f32
    }
    
    /// Precision
    @native("train::metrics::precision")
    pub fn precision(predictions: tensor.Tensor, targets: tensor.Tensor) -> f32 {
        // True positives / (True positives + False positives)
    }
    
    /// Recall
    @native("train::metrics::recall")
    pub fn recall(predictions: tensor.Tensor, targets: tensor.Tensor) -> f32 {
        // True positives / (True positives + False negatives)
    }
    
    /// F1 score
    pub fn f1_score(predictions: tensor.Tensor, targets: tensor.Tensor) -> f32 {
        let p = precision(predictions, targets)
        let r = recall(predictions, targets)
        2.0 * (p * r) / (p + r + 1e-8)
    }
    
    /// Confusion matrix
    @native("train::metrics::confusion_matrix")
    pub fn confusion_matrix(predictions: tensor.Tensor, targets: tensor.Tensor, num_classes: u64) -> tensor.Tensor {
        // Returns [num_classes, num_classes] matrix
    }
    
    /// Mean absolute error (regression)
    pub fn mae(predictions: tensor.Tensor, targets: tensor.Tensor) -> f32 {
        (predictions - targets).abs().mean().item()
    }
    
    /// Root mean squared error (regression)
    pub fn rmse(predictions: tensor.Tensor, targets: tensor.Tensor) -> f32 {
        ((predictions - targets).pow(2.0).mean()).sqrt().item()
    }
    
    /// RÂ² score (regression)
    @native("train::metrics::r2_score")
    pub fn r2_score(predictions: tensor.Tensor, targets: tensor.Tensor) -> f32 {
        // 1 - (SS_res / SS_tot)
    }
}

// ============================================================================
// CALLBACKS
// ============================================================================

pub trait Callback {
    fn on_epoch_begin(self, epoch: u64) {}
    fn on_epoch_end(self, epoch: u64, metrics: collections.HashMap<str, f32>) {}
    fn on_batch_begin(self, batch: u64) {}
    fn on_batch_end(self, batch: u64, loss: f32) {}
}

/// Early stopping callback
pub struct EarlyStopping {
    patience: u64,
    min_delta: f32,
    best_loss: f32,
    counter: u64,
}

impl EarlyStopping {
    pub fn new(patience: u64 = 5, min_delta: f32 = 0.0) -> EarlyStopping {
        EarlyStopping {
            patience: patience,
            min_delta: min_delta,
            best_loss: f32.INFINITY,
            counter: 0,
        }
    }
    
    pub fn should_stop(self, val_loss: f32) -> bool {
        if val_loss < self.best_loss - self.min_delta {
            self.best_loss = val_loss
            self.counter = 0
            false
        } else {
            self.counter += 1
            self.counter >= self.patience
        }
    }
}

/// Learning rate scheduler callback
pub struct LRSchedulerCallback {
    scheduler: Box<dyn optim.LRScheduler>,
}

impl LRSchedulerCallback {
    pub fn new(scheduler: Box<dyn optim.LRScheduler>) -> LRSchedulerCallback {
        LRSchedulerCallback { scheduler: scheduler }
    }
}

impl Callback for LRSchedulerCallback {
    fn on_epoch_end(self, epoch: u64, metrics: collections.HashMap<str, f32>) {
        self.scheduler.step()
    }
}

// ============================================================================
// MIXED PRECISION TRAINING
// ============================================================================

pub mod amp {
    /// Automatic mixed precision context
    pub struct GradScaler {
        scale: f32,
        growth_factor: f32,
        backoff_factor: f32,
        growth_interval: u64,
    }
    
    impl GradScaler {
        pub fn new() -> GradScaler {
            GradScaler {
                scale: 65536.0,  // 2^16
                growth_factor: 2.0,
                backoff_factor: 0.5,
                growth_interval: 2000,
            }
        }
        
        @native("train::amp::scale")
        pub fn scale(self, loss: tensor.Tensor) -> tensor.Tensor {
            loss * self.scale
        }
        
        @native("train::amp::unscale")
        pub fn unscale_(self, optimizer: &mut dyn optim.Optimizer) {
            // Unscale gradients before clipping
        }
        
        @native("train::amp::step")
        pub fn step(self, optimizer: &mut dyn optim.Optimizer) {
            // Optimizer step with gradient scaling
        }
        
        pub fn update(self) {
            // Update scale factor
        }
    }
}

// ============================================================================
// DISTRIBUTED TRAINING (placeholder)
// ============================================================================

pub mod distributed {
    /// Initialize distributed training
    @native("train::distributed::init")
    pub fn init_process_group(backend: str = "nccl", world_size: u64 = 1, rank: u64 = 0) {
        // Initialize distributed backend (NCCL, Gloo, MPI)
    }
    
    /// Wrap model for data parallelism
    @native("train::distributed::ddp")
    pub fn DistributedDataParallel(model: Box<dyn nn.Module>) -> Box<dyn nn.Module> {
        // Wrap model for DDP
    }
}

// ============================================================================
// SIMPLE TRAINING LOOP (convenience function)
// ============================================================================

/// Simple training loop for quick experiments
pub fn train_simple(
    model: Box<dyn nn.Module>,
    train_data: (tensor.Tensor, tensor.Tensor),
    val_data: Option<(tensor.Tensor, tensor.Tensor)> = None,
    epochs: u64 = 10,
    batch_size: u64 = 32,
    learning_rate: f32 = 0.001,
    device: tensor.Device = tensor.Device.CPU
) {
    // Create dataset
    let (train_x, train_y) = train_data
    let train_dataset = data.TensorDataset.new(train_x, train_y)
    let train_loader = data.DataLoader.new(train_dataset, batch_size: batch_size, shuffle: true)
    
    // Create optimizer and loss
    let optimizer = optim.Adam.new(model.parameters(), lr: learning_rate)
    let loss_fn = nn.CrossEntropyLoss.new()
    
    // Create trainer
    let config = TrainConfig {
        epochs: epochs,
        learning_rate: learning_rate,
        batch_size: batch_size,
        device: device,
        ..TrainConfig.default()
    }
    
    let trainer = Trainer.new(model, optimizer, loss_fn, config)
    
    // Create val loader if provided
    let val_loader = if let Some((val_x, val_y)) = val_data {
        let val_dataset = data.TensorDataset.new(val_x, val_y)
        Some(data.DataLoader.new(val_dataset, batch_size: batch_size))
    } else {
        None
    }
    
    // Train
    trainer.fit(train_loader, val_loader)
}
